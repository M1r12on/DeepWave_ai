# ğŸµ DeepWave AI â€“ Klassifikation urbaner Sounds mit Feature-Engineering & PyTorch

---

## ğŸ” ProjektÃ¼berblick

Dieses Projekt ist ein vollstÃ¤ndiger Audio-Classifizierungs-Workflow, der **synthetische Zuordnungen urbaner GerÃ¤usche** mittels des Datensatzes [UrbanSound8K](https://urbansounddataset.weebly.com/urbansound8k.html) analysiert, verarbeitet und klassifiziert.

Ziel: Eine robuste Pipeline zur Feature-Extraktion, Trainingsdatenerstellung und neuronaler Klassifikation, die **C++-kompatibel** (TorchScript, ONNX) exportiert werden kann.

---

## ğŸ“š Inhaltsverzeichnis

- [Projektstruktur](#-projektstruktur)
- [Datensatz](#-datensatz)
- [Einrichtung (virtuelle Umgebung)](#ï¸-einrichtung-virtuelle-umgebung)
- [AbhÃ¤ngigkeiten installieren](#-abhÃ¤ngigkeiten-installieren)
- [Verarbeitungs-Pipeline im Detail](#-verarbeitungs-pipeline-im-detail)
- [Architektur des Netzwerks](#-architektur-des-netzwerks)
- [Exportformate fÃ¼r Deployment](#ï¸-exportformate-fÃ¼r-deployment)
- [Evaluation mit ONNX & Confusion Matrix](#-evaluation-mit-onnx--confusion-matrix)
- [FAQ / Fehlersuche](#-faq--fehlersuche)

---

## ğŸ“ Projektstruktur

```plaintext
DEEPWAVE_AI/
â”œâ”€â”€ audio/                  # Audio-Files (UrbanSound8K)
â”‚   â”œâ”€â”€ fold1/ â€¦ fold10/
â”œâ”€â”€ metadata/
â”‚   â””â”€â”€ UrbanSound8K.csv   # CSV mit Metadaten zu allen Audiofiles
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/              # NPY-Features, JSON-Dateien etc.
â”‚   â”œâ”€â”€ 01_filter_and_label.py
â”‚   â”œâ”€â”€ 02_split_synth_classes.py
â”‚   â”œâ”€â”€ 03_extract_cpp_features.py
â”‚   â”œâ”€â”€ 04_train_classifier.py
â”‚   â”œâ”€â”€ 05_confusion_matrix_val.py
â”‚   â”œâ”€â”€ 06_predict_single_file.py
â”‚   â”œâ”€â”€ 07_export_training_stats.py
â”œâ”€â”€ requirements.txt       # Python-AbhÃ¤ngigkeiten
â””â”€â”€ README.md              # Dieses Dokument
```

---

## ğŸ§ Datensatz

Der verwendete Datensatz ist [**UrbanSound8K**](https://urbansounddataset.weebly.com/urbansound8k.html) â€“ ein realer, annotierter Datensatz mit 8732 Audio-Dateien aus 10 GerÃ¤uschklassen.

### ğŸ“¥ Download

1. Besuche: https://urbansounddataset.weebly.com/urbansound8k.html
2. Lade die ZIP-Datei herunter (ca. 6 GB)
3. Extrahiere:
   - Ordner `fold1` bis `fold10` â†’ nach `audio/`
   - Datei `UrbanSound8K.csv` â†’ nach `metadata/`

### ğŸ¯ Zielklassen (Subset)

| Originalklasse     | Mapping       |
|--------------------|---------------|
| `siren`            | `Lead`        |
| `dog_bark`         | `Pluck`       |
| `engine_idling`    | `Bass`        |
| `street_music`     | `Pad`         |

---

## âš™ï¸ Einrichtung (virtuelle Umgebung)

### 1. Erstelle und aktiviere die virtuelle Umgebung

#### ğŸ’» Windows:
```bash
python -m venv .venv
.venv\Scripts\activate
```

#### ğŸ§ macOS / Linux:
```bash
python3 -m venv .venv
source .venv/bin/activate
```

---

## ğŸ“¦ AbhÃ¤ngigkeiten installieren

```bash
pip install -r requirements.txt
```

### Beispiel `requirements.txt`:

```txt
numpy
pandas
tqdm
soundfile
matplotlib
scikit-learn
torch
onnxruntime
```

---

## ğŸš€ Verarbeitungs-Pipeline im Detail

### 1. Klassen filtern & labeln

```bash
python src/01_filter_and_label.py
```

â†’ Erzeugt `filtered_data.json` mit Pfad+Label-Mapping

### 2. Splitten in Train/Val

```bash
python src/02_split_synth_classes.py
```

â†’ Erstellt `train_data.json` & `val_data.json` mit definiertem VerhÃ¤ltnis.

### 3. Feature-Extraktion

```bash
python src/03_extract_cpp_features.py
```

â†’ Extrahiert 8 Features pro Datei (Zeit- & Frequenzbereich). Speichert `.npy`-Dateien.

### 4. Modell trainieren

```bash
python src/04_train_classifier.py
```

â†’ Trainiert ein 3-lagiges MLP-Modell (PyTorch) und exportiert als `.pt` und `.traced.pt`

### 5. Confusion Matrix + Report

```bash
python src/05_confusion_matrix_val.py
```

â†’ Zeigt Matrix + Precision, Recall, F1 pro Klasse

### 6. Vorhersage einer Datei

```bash
python src/06_predict_single_file.py
```

â†’ Nutzt ONNX-Modell zur Inferenz einer WAV-Datei aus `val_data.json`

### 7. Training Stats exportieren

```bash
python src/07_export_training_stats.py
```

â†’ Exportiert `cpp_mean.npy`, `cpp_std.npy` und `float mean[] = {...}`

---

## ğŸ§  Architektur des Netzwerks

```text
Input: 8 Features
â†“
Linear(8 â†’ 128) + ReLU + Dropout(0.3)
â†“
Linear(128 â†’ 64) + ReLU + Dropout(0.2)
â†“
Linear(64 â†’ 4)
â†“
Softmax (via CrossEntropyLoss)
```

---

## ğŸ› ï¸ Exportformate fÃ¼r Deployment

| Format              | Datei                            | Ziel           |
|---------------------|----------------------------------|----------------|
| `TorchScript`       | `synth_classifier_cpp_traced.pt`| PyTorch C++    |
| `ONNX`              | `synth_classifier_cpp.onnx`     | ONNX Runtime   |
| `Normierung`        | `cpp_mean.npy`, `cpp_std.npy`   | Normalisierung |

---

## ğŸ“Š Evaluation mit ONNX & Confusion Matrix

Nach dem Training kannst du eine Evaluation mit ONNX durchfÃ¼hren.

### Beispiel: Konfusionsmatrix

![Confusion Matrix â€“ Validation Set](confusion.png)

**Legende:**
- Diagonale â†’ korrekt
- Off-Diagonale â†’ Verwechslung

| Klasse | Genauigkeit     | HÃ¤ufige Verwechslung         |
|--------|------------------|------------------------------|
| Lead   | 106/150 (70.7%) | oft mit Pad verwechselt (26Ã—) |
| Pluck  | 105/150 (70.0%) | etwas mit Pad (22Ã—)           |
| Bass   | 120/150 (80.0%) | gut erkannt                   |
| Pad    | 109/150 (72.7%) | oft mit Bass (21Ã—) verwechselt|

---

## â“ FAQ / Fehlersuche

- **Dateien nicht gefunden?** â†’ `audio/` Pfade prÃ¼fen
- **Leere Feature-Dateien?** â†’ Stille WAVs werden Ã¼bersprungen
- **ONNX Probleme?** â†’ Input-Shape `[1, 8]` prÃ¼fen

---

## ğŸ“œ Lizenz

UrbanSound8K Â© BY-NC Lizenz  
Projekt zu Forschungs- und Lernzwecken.